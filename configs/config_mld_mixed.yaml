# configs/config_mld_mixed.yaml
# 这是我们为混合训练任务专门设计的全新配置文件。
# 它将驱动我们的新数据流、新模型架构和新的微调逻辑。

####################################
# 实验设置 (Experiment Settings)
####################################

# 实验名称，会用作输出文件夹的名字
NAME: finetune_mld_with_text_v1
# Debug 模式，设为 True 时会使用极少量数据，方便快速测试流程
DEBUG: False
# 加速器类型: 'gpu' 或 'cpu'
ACCELERATOR: 'gpu'
# 使用的 GPU 设备索引，例如 [0] 或 [0, 1]
DEVICE: [0]

#####################################
# 训练设置 (Training Settings)
#####################################
TRAIN:
  # 模型阶段，在我们的微调任务中，固定为 'diffusion'
  STAGE: diffusion
  # [核心] 数据集名称，'mixed' 将激活我们的 MixedDataModule
  DATASETS: ['mixed']
  # 数据加载器的工作线程数
  NUM_WORKERS: 8
  # 训练批次大小
  BATCH_SIZE: 128
  # 微调的总轮数
  END_EPOCH: 500

  # [核心] 指向你下载的、原始的 MCM-LDM Denoiser 预训练权重
  # 这是我们微调的起点
  PRETRAINED: "checkpoints/denoiser_checkpoint/denoiser.ckpt"
  # [核心] 指向预训练的 VAE 模型权重
  PRETRAINED_VAE: "checkpoints/vae_checkpoint/vae7.ckpt"

  # [核心] 差分学习率配置
  OPTIM:
    TYPE: AdamW
    LR_CONFIG:
      # 1. 新增的 CrossAttention 层，使用最大学习率从头训练
      - { name: "cross_attn", layers: "cross_attn", lr: 1.0e-4 }
      # 2. Denoiser 的其余部分，使用小学习率进行微调
      - { name: "denoiser", layers: "denoiser", lr: 1.0e-5 }
      # 3. [可选，但推荐] VAE 也可以用极小的学习率微调，以适应数据，但我们计划冻结它，所以这里不生效
      # - { name: "vae", layers: "vae", lr: 1.0e-6 }

#####################################
# 验证设置 (Validation Settings)
#####################################
EVAL:
  # 验证集，我们的 DataModule 会使用 HumanML3D 的 val split
  DATASETS: ['humanml3d']
  # 验证批次大小
  BATCH_SIZE: 32
  SPLIT: val # 固定为 'val'

#####################################
# 数据集设置 (Dataset Settings)
#####################################
DATASET:
  JOINT_TYPE: 'humanml3d'
  NFEATS: 263
  NJOINTS: 22
  # [核心] 激活 MixedDataModule 的开关
  TYPE: 'mixed'
  # [核心] 词向量化器 (Glove) 的路径
  WORD_VERTILIZER_PATH: "deps/t2m/glove/"

  # [核心] 混合数据集的配置
  MIXED:
    # 比例: [HumanML3D, 100Style]。加起来最好等于 BATCH_SIZE
    BATCH_RATIO: [108, 20] 
    # BATCH_RATIO: [2, 2]

  # [核心] HumanML3D 数据集的配置
  HUMANML3D:
    ROOT: "/root/autodl-tmp/MyRepository/MCM-LDM/datasets/humanml3d"
    SAMPLER: {MAX_LEN: 196, MIN_LEN: 40, MAX_TEXT_LEN: 20}
    UNIT_LEN: 4
    MIN_FILTER_LEN: 40
    MAX_FILTER_LEN: 200 # 根据我们的数据分析结果设定
  
  # [核心] 100Style 数据集的配置
  STYLE100:
    ROOT: "/root/autodl-tmp/MyRepository/MCM-LDM/datasets/100StyleDataset"
    SAMPLER: {MAX_LEN: 196, MIN_LEN: 40, MAX_TEXT_LEN: 20}
    UNIT_LEN: 4
    MIN_FILTER_LEN: 40
    MAX_FILTER_LEN: 720 # 根据我们的数据分析结果设定

#####################################
# 模型设置 (Model Settings)
#####################################
model:
  # --- VAE 和 Denoiser 的骨架参数 (与原始配置保持一致) ---
  vae: true
  model_type: mld
  condition: 'text'
  latent_dim: [7, 256]
  ff_size: 1024
  num_layers: 9
  num_head: 4
  droupout: 0.1 # 原文是 dropout，这里保持拼写错误以兼容
  activation: gelu
  t2m_path: 'deps/t2m/t2m'
  
  # --- 推理时 Classifier-Free Guidance 的默认参数 ---
  guidance_scale: 5.0
  guidance_uncondp: 0.25

  # [核心] Denoiser 的专属配置，将通过 **kwargs 传入
  denoiser:
    # 激活我们新的 CrossAttention 通路
    use_text_condition: True
    # CLIP 文本特征的维度 (ViT-B/32 对应 512)
    clip_feature_dim: 512

#####################################
# 日志与保存设置 (Logger & Checkpoint Settings)
#####################################
LOGGER:
  SACE_CHECKPOINT_EPOCH: 50 # 每 100 个 epoch 保存一次模型
  LOG_EVERY_STEPS: 1
  VAL_EVERY_STEPS: 1000 # 每 500 个训练步，运行一次验证
  TENSORBOARD: True
  WANDB:
    PROJECT: null # 如果你用 wandb，请填写项目名，例如 "mld-finetune"
    OFFLINE: True # 设为 False 以在线记录
    RESUME_ID: null

# --- 其他配置 (LOSS, METRIC, TEST 等) 保持与原始文件一致即可 ---
# --- 为完整性，我将它们也复制过来 ---

METRIC:
  TYPE: ['TemosMetric', 'TM2TMetrics']

LOSS:
  TYPE: mld
  LAMBDA_LATENT: 1.0e-5
  LAMBDA_KL: 1.0e-4
  LAMBDA_REC: 1.0
  LAMBDA_GEN: 1.0
  LAMBDA_CROSS: 1.0
  LAMBDA_CYCLE: 0.0
  LAMBDA_PRIOR: 0.0
  DIST_SYNC_ON_STEP: False

TEST:
  CHECKPOINTS: '' # 微调后，将这里指向你最好的新 checkpoint
  DATASETS: ['humanml3d']
  SPLIT: test
  BATCH_SIZE: 32